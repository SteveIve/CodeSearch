当前存在的问题:
1. 在过滤的时候效率尤为低下
2. 在过滤score < 0 的情况时不太稳定, 可能产生过滤失败的情况

解决思路:
1. 效率低下可以利用多线程, 利用文件指针, 每个线程相距大约10000行, 这样同时处理, 减少IO等待时间. 同时, 在旧文件的基础上新增文件, 不会产生读脏数据的情况.
2. 当前, 原始latin1和修改后的UTF-8编码在测试数据上都可通过, 考虑对初始latin1编码文件修改后一律采用UTF-8编码.

当前最大的问题是IO读写消耗的时间太多, 所有操作发生在内存中, 利用大内存的优势每次处理完之后用一个线程进行磁盘写入

根据不同的tag, 统计所有出现的词数, 排除疑问词/冠词
